#!/usr/bin/env node
/**
 * Generate syntax_mapping.json from parser-ontology.ttl
 *
 * This script:
 * 1. Parses parser-ontology.ttl (which imports V3 from https://clearhead.us/vocab/actions/v3)
 * 2. Fetches V3 OWL ontology and SHACL shapes from web
 * 3. Extracts syntax annotations (symbols, grammar rules, etc.)
 * 4. Extracts SHACL constraints (values, patterns, min/max)
 * 5. Generates syntax_mapping.json
 *
 * This keeps the parser repo independent - it fetches everything it needs from
 * the published vocabulary, no coupling to the ontology repo.
 *
 * Usage:
 *   node scripts/generate-syntax-mapping.js [--output path/to/output.json]
 */

const fs = require('fs');
const path = require('path');
const https = require('https');

// Simple RDF/Turtle parser (minimal implementation for our needs)
// For production, could use n3.js or rdflib.js
class SimpleTurtleParser {
    constructor() {
        this.triples = [];
        this.prefixes = {};
    }

    parse(content) {
        const lines = content.split('\n');
        let currentSubject = null;
        let currentPredicate = null;

        for (let line of lines) {
            line = line.trim();

            // Skip comments and empty lines
            if (line.startsWith('#') || line.length === 0) continue;

            // Parse prefix declarations
            if (line.startsWith('@prefix')) {
                const match = line.match(/@prefix\s+(\w+):\s+<([^>]+)>/);
                if (match) {
                    this.prefixes[match[1]] = match[2];
                }
                continue;
            }

            // Parse triples (simplified - handles our specific format)
            // Format: subject predicate object .
            // or:     predicate object .  (continues previous subject)

            // For now, let's use a more robust approach - just extract what we need
            // Look for parser annotations
            const annotations = this.extractAnnotations(line);
            if (annotations) {
                this.triples.push(annotations);
            }
        }

        return this.triples;
    }

    extractAnnotations(line) {
        // Match patterns like: actions:hasPriority parser:symbol "!" ;
        const match = line.match(/^([\w:]+)\s+(parser:\w+)\s+["']([^"']+)["']/);
        if (match) {
            const [, subject, predicate, object] = match;
            return {
                subject: this.expandPrefix(subject),
                predicate: this.expandPrefix(predicate),
                object: object
            };
        }
        return null;
    }

    expandPrefix(prefixed) {
        const [prefix, local] = prefixed.split(':');
        if (this.prefixes[prefix]) {
            return this.prefixes[prefix] + local;
        }
        return prefixed;
    }
}

/**
 * Fetch content from URL
 */
function fetchUrl(url) {
    return new Promise((resolve, reject) => {
        https.get(url, (res) => {
            let data = '';
            res.on('data', (chunk) => data += chunk);
            res.on('end', () => {
                if (res.statusCode === 200) {
                    resolve(data);
                } else {
                    reject(new Error(`HTTP ${res.statusCode}: ${url}`));
                }
            });
        }).on('error', reject);
    });
}

/**
 * Load and parse parser ontology (local file)
 */
function loadParserOntology(filePath) {
    console.log(`üìñ Loading parser ontology from ${filePath}...`);
    const content = fs.readFileSync(filePath, 'utf8');

    const annotations = { _structures: {}, _utilityPatterns: {}, _grammarMetadata: {}, _depthConstraint: {} };
    const lines = content.split('\n');
    let currentProperty = null;
    let inStructureBlock = false;
    let currentStructureName = null;

    for (const line of lines) {
        // Check for start of a structure block
        // Only match structure definitions (not rdfs:subClassOf references)
        const structureStartMatch = line.match(/^parser:(\w+GrammarStructure)\s+a\s+owl:Class/);
        if (structureStartMatch) {
            // Only process Root and Child structures, not the parent ActionGrammarStructure
            if (structureStartMatch[1] === 'RootActionGrammarStructure' || structureStartMatch[1] === 'ChildActionGrammarStructure') {
                currentProperty = null; // End property block
                inStructureBlock = true;
                currentStructureName = structureStartMatch[1].includes('Root') ? 'root_action' : 'child_action';
                annotations._structures[currentStructureName] = [];
            }
            continue;
        }

        // Check for end of a structure block
        if (inStructureBlock && line.includes(') .')) {
            inStructureBlock = false;
            currentStructureName = null;
            continue;
        }

        // If in a structure block, parse the ordered properties
        if (inStructureBlock) {
            const orderedPropMatch = line.match(/\[\s*parser:grammarRuleName\s+"([^"]+)"\s*;\s*parser:isRequired\s+"(true|false)"/);
            if (orderedPropMatch) {
                annotations._structures[currentStructureName].push({
                    rule: orderedPropMatch[1],
                    required: orderedPropMatch[2] === 'true'
                });
            }
            continue;
        }

        // Match property declarations: actions:hasProperty or schema:name
        const propMatch = line.match(/^(actions:\w+|schema:\w+)\s*$/);
        if (propMatch) {
            currentProperty = propMatch[1];
            if (!annotations[currentProperty]) {
                annotations[currentProperty] = {};
            }
            continue;
        }

        if (!currentProperty) continue;

        // Match annotations
        const symbolMatch = line.match(/parser:symbol\s+\"([^\"]*)\"/);
        if (symbolMatch) {
            annotations[currentProperty].symbol = symbolMatch[1];
        }

        const ruleMatch = line.match(/parser:grammarRuleName\s+\"([^\"]+)\"/);
        if (ruleMatch) {
            annotations[currentProperty].grammarRuleName = ruleMatch[1];
        }

        const typeMatch = line.match(/parser:ruleType\s+\"([^\"]+)\"/);
        if (typeMatch) {
            annotations[currentProperty].ruleType = typeMatch[1];
        }

        const contextMatch = line.match(/parser:contextLevel\s+\"([^\"]+)\"/);
        if (contextMatch) {
            annotations[currentProperty].contextLevel = contextMatch[1];
        }

        const hintMatch = line.match(/parser:formatHint\s+\"([^\"]+)\"/);
        if (hintMatch) {
            annotations[currentProperty].formatHint = hintMatch[1];
        }

        const exampleMatch = line.match(/parser:example\s+\"([^\"]+)\"/);
        if (exampleMatch) {
            annotations[currentProperty].example = exampleMatch[1];
        }

        const repeatMatch = line.match(/parser:canRepeat\s+\"(\w+)\"/);
        if (repeatMatch && repeatMatch[1] === 'true') {
            annotations[currentProperty].canRepeat = true;
        }

        const computedMatch = line.match(/parser:isComputed\s+\"(\w+)\"/);
        if (computedMatch && computedMatch[1] === 'true') {
            annotations[currentProperty].computed = true;
        }

        const usesSyntaxMatch = line.match(/parser:usesSyntax\s+parser:(\w+)/);
        if (usesSyntaxMatch) {
            annotations[currentProperty].special_syntax = usesSyntaxMatch[1];
        }

        // Value mappings
        const ontologyValueMatch = line.match(/parser:ontologyValue\s+\"([^\"]+)\"/);
        const syntaxValueMatch = line.match(/parser:syntaxValue\s+\"([^\"]+)\"/);

        // State/parenthesis mappings
        const parenMatch = line.match(/(actions:\w+)\s+parser:parenSymbol\s+\"([^\"]+)\"/);
        if (parenMatch) {
            if (!annotations._stateMappings) annotations._stateMappings = {};
            annotations._stateMappings[parenMatch[1]] = parenMatch[2];
        }

        // Grammar metadata
        if (line.includes('parser:ActionsGrammarMetadata')) {
            currentProperty = '_grammarMetadata';
            continue;
        }

        // Depth constraint
        if (line.includes('parser:DepthConstraint')) {
            currentProperty = '_depthConstraint';
            continue;
        }

        // Utility patterns (iso_date, iso_time, iso_date_time, safe_text)
        // Only match our specific utility patterns, not other DatatypeProperty definitions
        const utilityMatch = line.match(/^parser:(iso_date|iso_time|iso_date_time|safe_text)\s+a\s+owl:DatatypeProperty/);
        if (utilityMatch) {
            const utilityName = utilityMatch[1];
            currentProperty = `_utility_${utilityName}`;
            annotations._utilityPatterns[utilityName] = {};
            continue;
        }

        // Parse utility pattern properties
        if (currentProperty && currentProperty.startsWith('_utility_')) {
            const utilityName = currentProperty.replace('_utility_', '');
            if (annotations._utilityPatterns[utilityName]) {
                const patternMatch = line.match(/parser:pattern\s+\"([^\"]+)\"/);
                if (patternMatch) {
                    annotations._utilityPatterns[utilityName].pattern = patternMatch[1];
                }
                const ruleNameMatch = line.match(/parser:grammarRuleName\s+\"([^\"]+)\"/);
                if (ruleNameMatch) {
                    annotations._utilityPatterns[utilityName].grammarRuleName = ruleNameMatch[1];
                }
                const ruleTypeMatch = line.match(/parser:ruleType\s+\"([^\"]+)\"/);
                if (ruleTypeMatch) {
                    annotations._utilityPatterns[utilityName].ruleType = ruleTypeMatch[1];
                }
                const repeatModeMatch = line.match(/parser:repeatMode\s+\"([^\"]+)\"/);
                if (repeatModeMatch) {
                    annotations._utilityPatterns[utilityName].repeatMode = repeatModeMatch[1];
                }
                const excludeMatch = line.match(/parser:exclude\s+\"([^\"]+)\"/);
                if (excludeMatch) {
                    annotations._utilityPatterns[utilityName].exclude = excludeMatch[1];
                }
            }
        }

        // Parse grammar metadata properties
        if (currentProperty === '_grammarMetadata') {
            const entryPointMatch = line.match(/parser:entryPoint\s+\"([^\"]+)\"/);
            if (entryPointMatch) {
                annotations._grammarMetadata.entryPoint = entryPointMatch[1];
            }
            const rootRuleMatch = line.match(/parser:rootRule\s+\"([^\"]+)\"/);
            if (rootRuleMatch) {
                annotations._grammarMetadata.rootRule = rootRuleMatch[1];
            }
            const repeatModeMatch = line.match(/parser:repeatMode\s+\"([^\"]+)\"/);
            if (repeatModeMatch) {
                annotations._grammarMetadata.repeatMode = repeatModeMatch[1];
            }
            const whitespaceMatch = line.match(/parser:whitespaceHandling\s+\"([^\"]+)\"/);
            if (whitespaceMatch) {
                annotations._grammarMetadata.whitespaceHandling = whitespaceMatch[1];
            }
            const conflictsMatch = line.match(/parser:conflictRules\s+\"([^\"]+)\"/);
            if (conflictsMatch) {
                annotations._grammarMetadata.conflictRules = conflictsMatch[1];
            }
        }

        // Parse depth constraint properties
        if (currentProperty === '_depthConstraint') {
            const minDepthMatch = line.match(/parser:minDepth\s+(\d+)/);
            if (minDepthMatch) {
                annotations._depthConstraint.minDepth = parseInt(minDepthMatch[1]);
            }
            const maxDepthMatch = line.match(/parser:maxDepth\s+(\d+)/);
            if (maxDepthMatch) {
                annotations._depthConstraint.maxDepth = parseInt(maxDepthMatch[1]);
            }
            const symbolMatch = line.match(/parser:depthSymbol\s+\"([^\"]+)\"/);
            if (symbolMatch) {
                annotations._depthConstraint.symbol = symbolMatch[1];
            }
            const ruleNameMatch = line.match(/parser:grammarRuleName\s+\"([^\"]+)\"/);
            if (ruleNameMatch) {
                annotations._depthConstraint.grammarRuleName = ruleNameMatch[1];
            }
        }
    }

    console.log(`   Found ${Object.keys(annotations).filter(k => !k.startsWith('_')).length} annotated properties`);
    console.log(`   Found ${Object.keys(annotations._structures).length} grammar structures`);
    console.log(`   Found ${Object.keys(annotations._utilityPatterns).length} utility patterns`);
    if (annotations._depthConstraint.maxDepth) {
        console.log(`   Found depth constraint: ${annotations._depthConstraint.minDepth}-${annotations._depthConstraint.maxDepth}`);
    }
    if (annotations._grammarMetadata.entryPoint) {
        console.log(`   Found grammar metadata: entry=${annotations._grammarMetadata.entryPoint}`);
    }
    return annotations;
}

/**
 * Generate syntax mapping from annotations
 */
function generateMapping(annotations) {
    console.log('\nüîß Generating syntax mapping...');

    const mapping = {
        metadata: {
            generated_from: 'parser-ontology.ttl',
            imports: 'https://clearhead.us/vocab/actions/v3',
            version: '1.0.0',
            generated_at: new Date().toISOString()
        },
        rule_types: {
            choice: 'Fixed set of values from constraints',
            pattern: 'Regex pattern validation',
            uuid_v7: 'Version 7 UUID format',
            date_time: 'ISO 8601 date/time format',
            integer: 'Numeric value with optional constraints',
            text: 'Free text with escaping rules',
            reference: 'Reference to another object',
            computed: 'Calculated from other properties'
        },
        properties: {},
        structures: {},
        state_mappings: {},
        special_syntax: {},
        utility_patterns: {},
        depth_constraint: {},
        grammar_metadata: {}
    };

    // Extract structures
    if (annotations._structures) {
        mapping.structures = annotations._structures;
        delete annotations._structures;
    }

    // Extract utility patterns
    if (annotations._utilityPatterns) {
        mapping.utility_patterns = annotations._utilityPatterns;
        delete annotations._utilityPatterns;
    }

    // Extract depth constraint
    if (annotations._depthConstraint) {
        mapping.depth_constraint = annotations._depthConstraint;
        delete annotations._depthConstraint;
    }

    // Extract grammar metadata
    if (annotations._grammarMetadata) {
        mapping.grammar_metadata = annotations._grammarMetadata;
        delete annotations._grammarMetadata;
    }

    // Extract state mappings
    if (annotations._stateMappings) {
        for (const [stateUri, symbol] of Object.entries(annotations._stateMappings)) {
            const stateName = stateUri.split(':')[1]; // Extract local name
            mapping.state_mappings[stateName] = symbol;
        }
        delete annotations._stateMappings;
    }

    // Process each property
    for (const [propUri, data] of Object.entries(annotations)) {
        if (propUri.startsWith('_')) continue; // Skip internal keys

        const propName = propUri.split(':')[1] || propUri.split('/').pop();

        const propEntry = {
            symbol: data.symbol || '',
            rule_type: data.ruleType || 'text',
            grammar_rule_name: data.grammarRuleName || propName,
            context: data.contextLevel || 'any_level'
        };

        if (data.formatHint) propEntry.format_hint = data.formatHint;
        if (data.example) propEntry.example = data.example;
        if (data.canRepeat) propEntry.can_repeat = true;
        if (data.computed) propEntry.computed = true;
        if (data.special_syntax) propEntry.special_syntax = data.special_syntax;

        mapping.properties[propName] = propEntry;
    }

    console.log(`   Generated ${Object.keys(mapping.properties).length} property mappings`);
    console.log(`   Generated ${Object.keys(mapping.structures).length} structure mappings`);
    console.log(`   Generated ${Object.keys(mapping.utility_patterns).length} utility patterns`);
    console.log(`   State mappings: ${Object.keys(mapping.state_mappings).length}`);
    if (mapping.depth_constraint.maxDepth) {
        console.log(`   Depth constraint: ${mapping.depth_constraint.minDepth}-${mapping.depth_constraint.maxDepth}`);
    }
    if (mapping.grammar_metadata.entryPoint) {
        console.log(`   Grammar metadata: entry=${mapping.grammar_metadata.entryPoint}, conflicts=${mapping.grammar_metadata.conflictRules}`);
    }

    return mapping;
}

/**
 * Main execution
 */
async function main() {
    const args = process.argv.slice(2);
    const outputPath = args.includes('--output')
        ? args[args.indexOf('--output') + 1]
        : 'syntax_mapping.json';

    const ontologyPath = args.includes('--ontology')
        ? args[args.indexOf('--ontology') + 1]
        : 'parser-ontology.ttl';

    console.log('üöÄ Syntax Mapping Generator (JavaScript)');
    console.log('=' + '='.repeat(59));

    try {
        // Load parser ontology (local file)
        const annotations = loadParserOntology(ontologyPath);

        // Note: For MVP, we're using the annotations directly from parser-ontology.ttl
        // In the future, we could fetch V3 from web and merge with SHACL shapes
        // to extract constraints (min/max values, patterns, etc.)

        // For now, let's manually add SHACL-derived constraints that we know exist
        // (This would come from fetching shapes.ttl in the full implementation)
        if (annotations['actions:hasPriority']) {
            annotations['actions:hasPriority'].values = ['1', '2', '3', '4'];
            annotations['actions:hasPriority'].min_value = 1;
            annotations['actions:hasPriority'].max_value = 4;
        }

        if (annotations['actions:hasRecurrenceFrequency']) {
            annotations['actions:hasRecurrenceFrequency'].values = ['DAILY', 'WEEKLY', 'MONTHLY', 'YEARLY'];
            annotations['actions:hasRecurrenceFrequency'].value_mappings = [
                { from: 'DAILY', to: 'D' },
                { from: 'WEEKLY', to: 'W' },
                { from: 'MONTHLY', to: 'M' },
                { from: 'YEARLY', to: 'Y' }
            ];
        }

        if (annotations['actions:hasDurationMinutes']) {
            annotations['actions:hasDurationMinutes'].min_value = 1;
            annotations['actions:hasDurationMinutes'].max_value = 10080;
        }

        // Generate mapping
        const mapping = generateMapping(annotations);

        // Add SHACL constraints to mapping
        for (const [propName, data] of Object.entries(annotations)) {
            if (propName.startsWith('_')) continue;
            const localName = propName.split(':')[1] || propName.split('/').pop();

            if (data.values && mapping.properties[localName]) {
                mapping.properties[localName].values = data.values;
            }
            if (data.min_value !== undefined && mapping.properties[localName]) {
                mapping.properties[localName].min_value = data.min_value;
            }
            if (data.max_value !== undefined && mapping.properties[localName]) {
                mapping.properties[localName].max_value = data.max_value;
            }
            if (data.value_mappings && mapping.properties[localName]) {
                mapping.properties[localName].value_mappings = data.value_mappings;
            }
        }

        // Special handling for state - generate values from state_mappings
        if (mapping.properties.hasState) {
            mapping.properties.hasState.values = Object.values(mapping.state_mappings);
        }

        // Special handling for context - add default pattern for list syntax
        if (mapping.properties.hasContext && !mapping.properties.hasContext.pattern) {
            mapping.properties.hasContext.pattern = '[a-zA-Z0-9_-]+(,[a-zA-Z0-9_-]+)*';
        }

        // Write output
        console.log(`\nüíæ Writing to ${outputPath}...`);
        fs.writeFileSync(outputPath, JSON.stringify(mapping, null, 2));

        console.log(`‚úÖ Generated ${outputPath}`);
        console.log(`\nüìä Summary:
`);
        console.log(`   ‚Ä¢ ${Object.keys(mapping.properties).length} properties mapped
`);
        console.log(`   ‚Ä¢ ${Object.keys(mapping.state_mappings).length} state symbols`);

        console.log('\n‚ú® Done!');
    } catch (error) {
        console.error(`\n‚ùå Error: ${error.message}`);
        process.exit(1);
    }
}

// Run if called directly
if (require.main === module) {
    main();
}

module.exports = { loadParserOntology, generateMapping };